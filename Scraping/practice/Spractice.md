## scraping practice

```python
with open('Python/Scraping/practice/simple.html') as html_file:
    soup = BeautifulSoup(html_file, 'lxml')
    
print(soup.prettify())

match = soup.h2.text
print(match) ## result = 'Article 1 Head line'

## going for text
source = requests.get("https://gamewith.net/genshin-impact/article/show/25134").text
soup = BeautifulSoup(source, 'lxml')
matchDiv = soup.find('div', class_='genshin_seiza').p.text

print(matchDiv)

## getting src
eulaVideo_src = soup.find('div', id='article-body').video['src']
print(eulaVideo_src)

## getting video id
eulaVideo_src = eulaVideo_src.split('/')[-1].split('.')[0]
print(eulaVideo_src) ## outcome '6dc40621ccb12b12cc1dfe8f4e5b6d88'

## my own video id
video_id = f'http://youtube.com/video?v={eulaVideo_src}'


## requests_html
from requests_html import HTML, HTMLSession ## use this one when you finna use an url 

with open('Python/Scraping/practice/simple.html', 'r') as html_file:
    source = html_file.read()
    html = HTML(html=source)

match = html.find('h2') ## you only can use (.find()) here
print(match)
print(match[0].html) ## <h2><a href="article_1.html">Article 1 Headline</a></h2>
print(match[0].text) ## Article 1 Headline

## iterations
articles = html.find('div.article')

for article in articles:
    headline = article.find('h2', first=True).text
    summary = article.find('p', first=True).text

    print(headline)
    print(summary)

## Using HTMLSession
session = HTMLSession()
r = session.get('https://coreyms.com/')
articles = r.html.find('article')

for article in articles:
    try:
        headline = article.find('.entry-title-link',first=True).text
        print(headline)

        text = article.find('.entry-content p', first=True).text
        print(text)

        contentSpan = article.find('.entry-content span', first=True)
        video_src = contentSpan.find('iframe', first=True).attrs['src']
        video_id = video_src.split('/')[-1].split('?')[0]
        yt_link = f'https://www.youtube.com/watch?v={video_id}'

    except Exception as e:
        yt_link = None
    
    print(yt_link)
    print()

## it shows all the links of the html
links = r.html.links ## or r.html.absolute_links

for link in links:
    print(link)

## grabbing javascript text
with open('Python/Scraping/practice/simple.html', 'r') as html_file:
    source = html_file.read()
    html = HTML(html=source)
    html.render() ## allows to read text generated by javascript